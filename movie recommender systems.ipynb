{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joonil/anaconda/envs/pytorch/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define attributes of u.item\n",
    "FieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "      'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "      'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "\n",
    "# Read the data into dataframes\n",
    "DataDf = pd.read_csv(\"ml-100k/u.data\", sep='\\t', names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "Itemdata = pd.read_csv(\"ml-100k/u.item\", sep='|', encoding = \"ISO-8859-1\", names=FieldsMovies)\n",
    "\n",
    "# Setups\n",
    "FindID = Itemdata.movieTitle.to_dict()  # key: movieID-1, value:movie title\n",
    "NumItems = len(DataDf.item_id.unique())\n",
    "NumUsers = len(DataDf.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataDf = DataDf.drop('timestamp', axis=1)\n",
    "DataDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>462.48475</td>\n",
       "      <td>425.530130</td>\n",
       "      <td>3.529860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.61442</td>\n",
       "      <td>330.798356</td>\n",
       "      <td>1.125674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.00000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.00000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.00000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id        item_id         rating\n",
       "count  100000.00000  100000.000000  100000.000000\n",
       "mean      462.48475     425.530130       3.529860\n",
       "std       266.61442     330.798356       1.125674\n",
       "min         1.00000       1.000000       1.000000\n",
       "25%       254.00000     175.000000       3.000000\n",
       "50%       447.00000     322.000000       4.000000\n",
       "75%       682.00000     631.000000       4.000000\n",
       "max       943.00000    1682.000000       5.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique users and items (movies) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 943\n",
      "Number of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Users: {}\\nNumber of Movies: {}\".format(NumUsers, NumItems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(DataDf, test_size=0.2)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildItemUserMatrix(dataDf):\n",
    "    '''\n",
    "    Input\n",
    "    - datadf: A pandas dataframe of movielens dataset\n",
    "\n",
    "    Ouput\n",
    "    - matrix: A 2d numpy array of Item-User Matrix (numItems x numUsers)\n",
    "    '''\n",
    "    dataMatrix = np.zeros((NumItems, NumUsers), dtype=np.int8)\n",
    "\n",
    "    # Populate the matrix based on the dataset\n",
    "    for (index, userID, itemID, rating) in dataDf.itertuples():\n",
    "        dataMatrix[itemID-1, userID-1] = rating\n",
    "    return dataMatrix\n",
    "\n",
    "def getSimilarMovies(similarity, movieID, k=5):\n",
    "    '''\n",
    "    Recommend k-number of similar movie by cosine similarity metric\n",
    "    '''\n",
    "    movieVec = similarity[movieID-1]\n",
    "    movieVec = np.delete(movieVec, movieID-1)\n",
    "    sortedIdx = np.argsort(movieVec)[::-1]\n",
    "    print(\"Did you like '{}'?\\n\".format(FindID[movieID-1]))\n",
    "    print(\"What we recommend for you\")\n",
    "    for i in range(k):\n",
    "        movietitle = FindID[sortedIdx[i+1]+1]\n",
    "        print(\"{}: {}\".format(i+1, movietitle))\n",
    "\n",
    "def whichMovie(movieID):\n",
    "    return FindID[movieID-1]\n",
    "\n",
    "def predictRatings(trainDf, similarity):\n",
    "    '''\n",
    "    Predict empty ratings by using item-cosine-similarity\n",
    "    '''\n",
    "    dataMatrix = buildItemUserMatrix(trainDf)\n",
    "    predictionMatrix = np.zeros((NumItems, NumUsers))\n",
    "    \n",
    "    # loop over non-rated items\n",
    "    for u in range(NumUsers):\n",
    "        userVector = dataMatrix[:,u]\n",
    "        nonzeros = userVector.nonzero()\n",
    "        itemRatings = userVector[nonzeros]\n",
    "        zeros = np.argwhere(userVector == 0).flatten()\n",
    "\n",
    "        for i in zeros:\n",
    "            # Get the similarity score for each of the items that provided rating by this user\n",
    "            itemSims = similarity[i,:][nonzeros]\n",
    "\n",
    "            if itemSims.sum() == 0:\n",
    "                continue\n",
    "            else:\n",
    "                #Predict score based on item-item similarity\n",
    "                predictionMatrix[i,u] = (itemRatings * itemSims).sum() / itemSims.sum()\n",
    "    \n",
    "    return predictionMatrix\n",
    "\n",
    "def recommendMovies(userID, **options):\n",
    "    '''\n",
    "    Recommend movies for the user with userID\n",
    "    '''\n",
    "    # Read options args\n",
    "    model = options.pop('model', None)\n",
    "    trainDf = options.pop('train_data', None)\n",
    "    similarity = options.pop('similarity', None)\n",
    "    predictionMatrix = options.pop('prediction_matrix', None)\n",
    "    k = options.pop('k', 10)\n",
    "    \n",
    "    if options:\n",
    "        raise TypeError(\"Invalid parameters passed: %s\" % str(options))\n",
    "\n",
    "    \n",
    "    \n",
    "    recMovies = []\n",
    "    \n",
    "    # if trained model was passed in\n",
    "    if model:\n",
    "        pairs = [ np.array([userID] * NumUsers),\n",
    "                 np.array([itemID for itemID in range(1, NumItems+1)]) ]\n",
    "        pred = model.predict(pairs)\n",
    "        argmaxIdx = np.argsort(pred, axis=0)[::-1].squeeze()\n",
    "        argmaxIdx = argmaxIdx[:k]\n",
    "\n",
    "        # Get the k-highest scored movies in the predictions list\n",
    "        for i in argmaxIdx:\n",
    "            recMovies.append(FindID[i])\n",
    "\n",
    "        return recMovies\n",
    "    \n",
    "    # if similarity matrix was passed in, use cosine similarity\n",
    "    elif similarity is not None:\n",
    "\n",
    "        # if trainDf is None, raise error\n",
    "        if trainDf is None:\n",
    "            raise BaseException(\"Invalid data types passed\")\n",
    "        \n",
    "        # if prediction matrix is None, calculate it\n",
    "        if predictionMatrix is None:\n",
    "            predictionMatrix = predictRatings(trainDf, similarity)\n",
    "         \n",
    "        userVector = predictionMatrix[:, userID-1]\n",
    "        argmaxIdx = np.argsort(userVector, axis=0)[::-1].squeeze()\n",
    "        \n",
    "        if len(argmaxIdx) >= k:\n",
    "            argmaxIdx = argmaxIdx[:k]\n",
    "        \n",
    "        # Get the k-highest scored movies in the predictions list\n",
    "        for i in argmaxIdx:\n",
    "            recMovies.append(FindID[i])\n",
    "\n",
    "        return recMovies\n",
    "\n",
    "def usersBestMovies(dataDf, userID):\n",
    "    '''\n",
    "    Find the best rated movies for the user\n",
    "    '''\n",
    "    # if the userID is not found in the data, print error message\n",
    "    if len(dataDf.loc[dataDf['user_id'] == userID]) == 0:\n",
    "        print(\"'User_ID {}' is not in our database!\".format(userID))\n",
    "        return\n",
    "    \n",
    "    # Return all the movies which were rated the highest score by the user\n",
    "    maxrating = dataDf.loc[dataDf['user_id']==userID].rating.max()\n",
    "    bestMovieIDs = dataDf.loc[(dataDf['user_id']==userID) &\n",
    "                            (dataDf['rating']==maxrating)].item_id\n",
    "    \n",
    "    # Store the best movies\n",
    "    bestMovies = []\n",
    "    for movieID in bestMovieIDs:\n",
    "        bestMovies.append(FindID[movieID-1])\n",
    "        \n",
    "    return bestMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix = buildItemUserMatrix(DataDf)\n",
    "similarity = cosine_similarity(dataMatrix)\n",
    "trainMatrix = buildItemUserMatrix(train)\n",
    "testMatrix = buildItemUserMatrix(test)\n",
    "pred_Matrix = predictRatings(train, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error 1.010567440981017\n",
      "Root Mean Square Error (rounded) 1.050951949424901\n"
     ]
    }
   ],
   "source": [
    "# add predicted scores in the test dataframe\n",
    "for ind, userID, itemID, rating in test.itertuples():\n",
    "    test.loc[ind, 'pred_cosSim'] = pred_Matrix[itemID-1, userID-1]\n",
    "\n",
    "rmse_similarity = np.sqrt(mean_squared_error(test.rating, test.pred_cosSim))\n",
    "rmse_similarity_round = np.sqrt(mean_squared_error(test.rating, np.round(test.pred_cosSim)))\n",
    "print(\"Root Mean Square Error {}\".format(rmse_similarity))\n",
    "print(\"Root Mean Square Error (rounded) {}\".format(rmse_similarity_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_latent_factors = 3\n",
    "\n",
    "movie_input = keras.layers.Input(shape=[1], name='Item')\n",
    "movie_embedding = keras.layers.Embedding(NumItems + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1], name='User')\n",
    "user_embedding = keras.layers.Embedding(NumUsers + 1, n_latent_factors,name='User-Embedding')(user_input)\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "prod = keras.layers.dot([movie_vec, user_vec], axes=1, name='DotProduct')\n",
    "model = keras.Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 3)         5049        Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 3)         2832        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 3)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 3)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DotProduct (Dot)                (None, 1)            0           FlattenMovies[0][0]              \n",
      "                                                                 FlattenUsers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,881\n",
      "Trainable params: 7,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 12.2668\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 4.7439\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 1.9624\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.3222\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 1.0867\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.9846\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.9360\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.9100\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.8952\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.8856\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.8791\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.8742\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.8708: 0s \n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.8679\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.8653\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.8631\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.8610\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.8586\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.8570\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.8545\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.8524\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.8499\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8470\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.8438\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.8402\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.8365\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.8319\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.8270\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.8225\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.8174\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.8121\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.8076\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.8027\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7985\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.7944\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.7908\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.7870\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.7838\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.7805\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7777\n",
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7747\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.7720\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7691\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 0.7665\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7641\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 0.7618\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7593\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.7572\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7553\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.7532\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7512\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.7494\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.7478\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.7464\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.7446\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.7433\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.7421\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 0.7412\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 6s 73us/step - loss: 0.7398\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.7386\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7378\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 7s 82us/step - loss: 0.7367\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.7359\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.7350\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7343\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 0.7332\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7323\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7320\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7312\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.7305\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.7297\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.7289\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.7285\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7278\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7273\n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7268\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.7264\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 0.7258\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7253\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7247\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.7242\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.7240\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.7235\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7230\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7227\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7224\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7217\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7214\n",
      "Epoch 89/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7212\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7207\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7205\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7200\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7198\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7195\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7192\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.7190\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.7187\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.7184\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.7181\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.7178\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losshist = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgAF8f/xd7YApLSv4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss history\n",
    "plt.plot(losshist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error 0.9491449008978493\n",
      "Mean Absolute Error 0.8592311690855685\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([test.user_id, test.item_id])\n",
    "rmse_factorize = np.sqrt(mean_squared_error(test.rating, y_pred))\n",
    "mae_factorize = np.sqrt(mean_absolute_error(test.rating, y_pred))\n",
    "print(\"Root Mean Square Error {}\".format(rmse_factorize))\n",
    "print(\"Mean Absolute Error {}\".format(mae_factorize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round up the predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error 0.9925976022538036\n",
      "Mean Absolute Error 0.8371081172704037\n"
     ]
    }
   ],
   "source": [
    "rmse_factorize_round = np.sqrt(mean_squared_error(test.rating, np.round(y_pred)))\n",
    "mae_factorize_round = np.sqrt(mean_absolute_error(test.rating, np.round(y_pred)))\n",
    "print(\"Root Mean Square Error {}\".format(rmse_factorize_round))\n",
    "print(\"Mean Absolute Error {}\".format(mae_factorize_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.constraints import non_neg\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(NumItems + 1, n_latent_factors, name='NonNegMovie-Embedding',\n",
    "                                        embeddings_constraint=non_neg())(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = keras.layers.Embedding(NumUsers + 1, n_latent_factors,name='NonNegUser-Embedding',\n",
    "                                        embeddings_constraint=non_neg())(user_input)\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "prod = keras.layers.dot([movie_vec, user_vec], axes=1, name='DotProduct')\n",
    "model = keras.Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.7195\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7186\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7185\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7183\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7178\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7180\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.7177\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 5s 64us/step - loss: 0.7174\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7174\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.7174\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7170\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.7168\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 6s 80us/step - loss: 0.7167\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 6s 75us/step - loss: 0.7164\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 6s 73us/step - loss: 0.7165\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 7s 83us/step - loss: 0.7162\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.7162\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7161\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7158\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7158\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7155\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7158\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.7154\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7151\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7150\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7151\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7149\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.7151\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7147\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7147\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7144\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7144\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7146\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7143\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7141\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7143\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7140\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7140\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7139\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7137\n",
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 5s 69us/step - loss: 0.7141\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 0.7137\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 0.7137\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7138\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.7134\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7135\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7133\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7133\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7130\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7135\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7130\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7131\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7130\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7131\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 5s 64us/step - loss: 0.7130\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7128\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.7126\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7128\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 5s 68us/step - loss: 0.7126\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7126\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7126\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 0.7124\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7126\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.7125\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7125\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7125\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7125\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7124\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7123\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7121\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7121\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.7122\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7123\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7121\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7118\n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7119\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7122\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7118\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7117\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 5s 68us/step - loss: 0.7118\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 0.7120\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7120\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.7118\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 6s 69us/step - loss: 0.7118\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.7118\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7118\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7116\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7116\n",
      "Epoch 89/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7117\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7115\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7117\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7114\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7116\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7114\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7114\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.7114\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7114\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.7114\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.7114\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 5s 68us/step - loss: 0.7111\n"
     ]
    }
   ],
   "source": [
    "history_nonneg = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error 0.9506555924150177\n",
      "Root Mean Square Error (rounded) 0.9958664569107647\n"
     ]
    }
   ],
   "source": [
    "y_pred_nonneg = model.predict([test.user_id, test.item_id])\n",
    "rmse_factorize = np.sqrt(mean_squared_error(test.rating, y_pred_nonneg))\n",
    "rmse_factorize_nonneg = np.sqrt(mean_squared_error(test.rating, np.round(y_pred_nonneg)))\n",
    "\n",
    "# Print out the RMSE\n",
    "print(\"Root Mean Square Error {}\".format(rmse_factorize))\n",
    "print(\"Root Mean Square Error (rounded) {}\".format(rmse_factorize_nonneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test.assign(pred_Factorization=np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred_cosSim</th>\n",
       "      <th>prediction_Factorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>2.266420</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>3.032868</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>851</td>\n",
       "      <td>693</td>\n",
       "      <td>5</td>\n",
       "      <td>3.829329</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>468</td>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "      <td>3.960365</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.564295</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  pred_cosSim  prediction_Factorization\n",
       "0      405      181       5     2.266420                       3.0\n",
       "1      857      892       3     3.032868                       2.0\n",
       "2      851      693       5     3.829329                       4.0\n",
       "3      468     1016       3     3.960365                       3.0\n",
       "4      625       22       3     3.564295                       4.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainBest = usersBestMovies(train, 1)\n",
    "testBest = usersBestMovies(test, 1)\n",
    "predBest_cossim = recommendMovies(1, train_data=train, similarity=similarity, prediction_matrix=pred_Matrix)\n",
    "predBest_factor = recommendMovies(1, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When Harry Met Sally... (1989)',\n",
       " 'Lone Star (1996)',\n",
       " 'Welcome to the Dollhouse (1995)',\n",
       " 'French Twist (Gazon maudit) (1995)',\n",
       " 'Haunted World of Edward D. Wood Jr., The (1995)',\n",
       " 'Mystery Science Theater 3000: The Movie (1996)',\n",
       " 'Wrong Trousers, The (1993)',\n",
       " 'Bound (1996)',\n",
       " 'Jean de Florette (1986)',\n",
       " 'Mars Attacks! (1996)',\n",
       " 'Good, The Bad and The Ugly, The (1966)',\n",
       " 'Professional, The (1994)',\n",
       " \"Monty Python's Life of Brian (1979)\",\n",
       " 'Crumb (1994)',\n",
       " '12 Angry Men (1957)',\n",
       " 'Princess Bride, The (1987)',\n",
       " 'Star Wars (1977)',\n",
       " 'Wallace & Gromit: The Best of Aardman Animation (1996)',\n",
       " 'Henry V (1989)',\n",
       " 'Chasing Amy (1997)',\n",
       " 'Graduate, The (1967)',\n",
       " 'Dolores Claiborne (1994)',\n",
       " 'Ridicule (1996)',\n",
       " 'Three Colors: Blue (1993)',\n",
       " 'Priest (1994)',\n",
       " 'Big Night (1996)',\n",
       " 'Eat Drink Man Woman (1994)',\n",
       " 'Return of the Jedi (1983)',\n",
       " 'Three Colors: Red (1994)',\n",
       " 'Chasing Amy (1997)',\n",
       " 'Clerks (1994)',\n",
       " 'Empire Strikes Back, The (1980)',\n",
       " 'Nikita (La Femme Nikita) (1990)',\n",
       " 'Pillow Book, The (1995)',\n",
       " 'Dead Man Walking (1995)',\n",
       " 'Monty Python and the Holy Grail (1974)',\n",
       " 'Nightmare Before Christmas, The (1993)',\n",
       " 'Gattaca (1997)',\n",
       " 'Contact (1997)',\n",
       " 'Aliens (1986)',\n",
       " 'Brazil (1985)',\n",
       " 'Breaking the Waves (1996)',\n",
       " 'Kolya (1996)',\n",
       " \"Antonia's Line (1995)\",\n",
       " 'Kids in the Hall: Brain Candy (1996)',\n",
       " 'Terminator 2: Judgment Day (1991)',\n",
       " \"Mr. Holland's Opus (1995)\",\n",
       " 'Jurassic Park (1993)',\n",
       " 'Swingers (1996)',\n",
       " 'Alien (1979)',\n",
       " 'Manon of the Spring (Manon des sources) (1986)',\n",
       " 'Godfather, The (1972)',\n",
       " 'Sleeper (1973)',\n",
       " 'Star Trek: The Wrath of Khan (1982)',\n",
       " 'Terminator, The (1984)',\n",
       " 'Groundhog Day (1993)',\n",
       " 'Cyrano de Bergerac (1990)',\n",
       " 'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)',\n",
       " 'Hoop Dreams (1994)',\n",
       " 'Back to the Future (1985)',\n",
       " 'Mighty Aphrodite (1995)',\n",
       " 'Hudsucker Proxy, The (1994)',\n",
       " 'Dead Poets Society (1989)',\n",
       " 'Toy Story (1995)',\n",
       " 'Young Frankenstein (1974)']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Searching for Bobby Fischer (1993)',\n",
       " 'Truth About Cats & Dogs, The (1996)',\n",
       " 'Shawshank Redemption, The (1994)',\n",
       " 'Amadeus (1984)',\n",
       " 'Blade Runner (1982)',\n",
       " 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)',\n",
       " 'Postino, Il (1994)',\n",
       " 'Maya Lin: A Strong Clear Vision (1994)',\n",
       " 'Delicatessen (1991)',\n",
       " 'Raiders of the Lost Ark (1981)',\n",
       " 'Remains of the Day, The (1993)',\n",
       " 'Fargo (1996)',\n",
       " 'Full Monty, The (1997)',\n",
       " 'Cinema Paradiso (1988)',\n",
       " 'Usual Suspects, The (1995)',\n",
       " 'Sling Blade (1996)']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cyclo (1995)',\n",
       " 'Little City (1998)',\n",
       " 'Coldblooded (1995)',\n",
       " 'Mamma Roma (1962)',\n",
       " 'King of New York (1990)',\n",
       " 'Office Killer (1997)',\n",
       " 'Substance of Fire, The (1996)',\n",
       " 'Ballad of Narayama, The (Narayama Bushiko) (1958)',\n",
       " \"C'est arriv prs de chez vous (1992)\",\n",
       " \"My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predBest_cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two or Three Things I Know About Her (1966)',\n",
       " 'In the Line of Duty 2 (1987)',\n",
       " 'Great Day in Harlem, A (1994)',\n",
       " 'Maya Lin: A Strong Clear Vision (1994)',\n",
       " 'Wallace & Gromit: The Best of Aardman Animation (1996)',\n",
       " 'Love and Death on Long Island (1997)',\n",
       " 'Godfather, The (1972)',\n",
       " 'High Noon (1952)',\n",
       " 'Godfather: Part II, The (1974)',\n",
       " 'Laura (1944)']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predBest_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend movies by using different systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendMovies(userID=1, train_data=train, similarity=similarity,\n",
    "                prediction_matrix=pred_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
